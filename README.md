# AI Journey — Becoming a Python AI Engineer  
Author: Ashu  

This repository documents my structured journey toward becoming a Python AI Engineer. The focus is on building strong data foundations, analytical thinking, and practical problem-solving skills.

---

## Phase 1: Data Mastery  
Objective: Develop expertise in data handling, cleaning, exploratory data analysis (EDA), and visualization.
Emphasis on understanding data behavior before building machine learning models.

---

## Week 1 (Days 1–7): Foundations (NumPy + Pandas)

Focus: Core data manipulation and analysis skills

- Day 1: Environment setup (venv, Jupyter Notebook, VS Code) and GitHub repository initialization  
- Day 2: NumPy arrays, slicing, reshaping, broadcasting  
- Day 3: NumPy statistics, aggregations, boolean masking  
- Day 4: Pandas Series and DataFrame, reading CSV/Excel/JSON  
- Day 5: Filtering, sorting, groupby operations  
- Day 6: Handling missing values, duplicates, and data type conversion  
- Day 7: Mini EDA project (data cleaning and extracting insights)

---

## Week 2 (Days 8–15): EDA and Visualization

Focus: Identifying patterns, relationships, and feature importance

- Day 8: Matplotlib basics (line plot, bar plot, histogram)  
- Day 9: Seaborn fundamentals  
  - countplot — Category frequency  
  - barplot — Average per category  
  - heatmap — Correlation analysis  
  - boxplot — Outliers and spread  
  - histplot — Distribution analysis  
  - scatterplot — Numeric relationship  
- Day 10: - Day 10: Correlation analysis, IQR-based outlier detection, skewness analysis, and statistical impact comparison (mean vs median)
- Day 11: Feature engineering basics (creating derived features)  
- Day 12: Full Exploratory Data Analysis — Titanic Dataset  
  - Survival analysis  
  - Feature relationship exploration (Sex, Class, Age, Fare, Embarked)  
  - Distribution analysis and pattern extraction  

- Day 13: Full Exploratory Data Analysis — Netflix Dataset  
  - Content type distribution (Movies vs TV Shows)  
  - Year-wise content growth trend  
  - Country-wise content production  
  - Ratings distribution analysis  
  - Genre frequency analysis  
  - Detection of data quality issues  
- Day 14: Documentation and visualization reporting  
- Day 15: Finalize Project 1 (Complete EDA Case Study)

---

## Tech Stack

- Python  
- NumPy  
- Pandas  
- Matplotlib  
- Seaborn  
- Jupyter Notebook  
- Git and GitHub  
- Scikit-learn (Next Phase: Machine Learning)

---

## Sample Visualizations

### Sales Comparison Plot
![Sales Plot](sales_comparison.png)

### Survival Rate by Class
![Survival Rate Chart](Survival_Rate.png)

---

## Purpose of This Repository

This project demonstrates:

- Structured and consistent learning  
- Strong data analysis fundamentals  
- Practical implementation through real-world EDA case studies  
- Pattern recognition and feature importance thinking  
- Clear documentation, structured workflow, and version control  

